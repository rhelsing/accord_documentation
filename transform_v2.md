# Transformations v2

## Introduction

The transformation step transforms data imported into the file pipeline for loading into the Accord IO system or for exporting to a new CSV file. The purpose of this step is to automate the movement of data between otherwise incompatable systems.

Use the transform task in your file pipeline to change values in your data file, based on the rules you establish in the task parameters. Write the rules in JSON format. A simple transformation that changes an abbreviated `employment_type` column to a spelled-out column (e.g., "FT" to "Full Time") might look like this:

```json
{
  "version": 2,
  "perform": {
    "convert": {
      "column": "employment_type",
      "formula": {
        "invert": {
          "FT": "Full Time",
          "PT": "Part Time"
      }
    }
  }
}
```

A more complex transformation may include calculations, field mappings, data queries, and other commands that you can use to build the transformations you need.

## Function List

Function | Brief Description
-------- | -----------------
[lookup](#perform-key-lookup) | Import a set of values from a reference table.
[dedup](#perform-key-dedup) | Remove duplicate records from the uploaded data.
[select](#perform-keys-select-and-reject) | Select (query) data from the Input based on a set of criteria.
[reject](#perform-keys-select-and-reject) | Reject data from the Input based on a set of criteria.
[convert](#perform-key-convert) | Use a formula to change the data contained in a column.
[derive](#perform-key-derive) | Create a new column in the Output and populate the column with values based on a formula.
[aggregate](#perform-key-aggregate) | Turn the Output into an aggregate report.
[map](#perform-key-map) | Define field mappings between Input and new columns generated through calculations, and Output.

## Definitions

The following terms will be used throughout this document:

<dl>
  <dt>Data File</dt>
  <dd>An Excel or csv file containing data. Field names are specified on the first row, with data contained in subsequent rows.</dd>
  <dt>Input</dt>
  <dd>A data file uploaded to Accord IO for acceptance into a File Pipeline</dd>
  <dt>Output</dt>
  <dd>A data file generated by a File Pipeline.</dd>
  <dt>File Pipeline</dt>
  <dd>A pre-defined series of tasks performed on uploaded data files.</dd>
</dl>

## Parameters

The parameters for your transformation are defined in JSON format, with the following top-level objects:

* `{ "save_output": "true" }` Set `save_output` to `true` to save the result of the transformation, or `false` to skip saving the result. This is a useful option if additional tasks are required in your File Pipeline after the Transformation step.
* `{ "version": 2 }` For transformations that follow the specification laid out in this document, make sure `version` is always set to `2`.
* `{ "perform": { ... }}` Specify the transforming actions to take on the Input in the `perform` object. This is the heart of the transformation step. Use the guide below to define the full tranformation.

### Perform Key: `lookup`

Import a set of values from a reference table. The `lookup` key can contain a single JSON object or an array of objects. Each object must contain three keys:

Key Name | Expected Value
-------- | --------------
input_key | The name of the key column in the input. Use an array if multiple columns need to be used as a key.
lookup_source | An object with `layout` or `file_drop` as the key name, and the name of the source as the value.
lookup_key | The name of the key column in the lookup source. Use an array if multiple columns need to be used as a key -- make sure the array contains the same number of fields as in the input_key, listed in the same order.

**Examples**

Single key lookup:

```json
{
  "lookup": {
    "input_key": "employee_id",
    "lookup_source": {
      "layout": "employee"
    },
    "lookup_key": "eid"
  }
}
```

Multiple key lookup:

```json
{
  "lookup": {
    "input_key": ["employee_id", "start_date"],
    "lookup_source": {
      "layout": "employee"
    },
    "lookup_key": ["eid", "start"]
  }
}
```

### Perform Key: `dedup`

Remove duplicate records from the uploaded data. This key can contain a single object or an array of objects. Each object must contain the following keys:

Key Name | Expected Value
-------- | --------------
column | The name of the input column. Use an array to specify multiple columns.
option | **Placeholder** (insert possible options here)

**Example**

```json
{
  "dedup": {
    "column": "ssn",
    "option": "accept_first"
  }
}
```

### Perform Keys: `select` and `reject`

Select (query) data from the Input based on a set of criteria, or reject data from the Input based on a set of criteria. These keys can contain a Condition Object or a set of Grouping Objects that each contain Condition Objects. It is possible to nest multiple Grouping Objects for more complex queries. A `select` key will ***include*** Input rows that match the criteria. A `reject` key will ***exclude*** Input rows that match the criteria. Each condition object must contain the following keys:

**Condition Object**

Key Name | Expected Value
-------- | --------------
column | The name of the column from the Input. Columns generated through a `lookup` or `derive` **placeholder** describe how the alias name will be generated.
eval | Any one of the following criteria names: <ul><li>is</li><li>starts_with</li><li>ends_with</li><li>contains</li><li>is_less_than</li><li>is_greater_than</li><li>matches</li><li>is_type</li><li>is_blank</li><li>is_present</li><li>has_lookup</li><li>lookup</li></ul>
value | The term you are searching for. If the `value` key contains an array, it is assumed that you are searching for any of the values contained in the array.<br><br>Please note the following restrictions, based on the value for the `eval` key:<ul><li>A `matches` eval will expect a Regular Expression **placeholder link** as the `value`. You should use this option only if you know what you're doing.</li><li>A `is_type` eval expects a known data type as the `value`. Possible values include: "Number", "Date", "String", "Name", "SSN", and "Boolean".</li><li>A `is_blank` or `is_present` eval does not require a `value`.</li><li>A `has_lookup` eval can only be used if a `lookup` Key is present. The value should match the value supplied for the `input_key`.</li></ul>

**Grouping Object**

The Grouping Object must contain either an "and" or an "or" key.

Key Name | Expected Value
-------- | --------------
and | (optional) An array of Condition Objects
or | (optional) An array of Condition Objects

**Examples**

Simple select and reject queries:

```json
{
  "select": {
    "column": "department_name",
    "eval": "is",
    "value": [ "accounting", "finance" ]
  },
  "reject": {
    "column": "employee_status",
    "eval": "is_greater_than",
    "value": 25000
  }
}
```

Select query with nested Grouping Objects:

```json
{
  "select": {
    "and": [
      {
        "column": "department_name",
        "eval": "is",
        "value": [ "accounting", "finance" ]
      },
      {
        "or": [
          {
            "column": "employee_job_function",
            "eval": "contains",
            "value": "money"
          },
          {
            "column": "employee_equipment",
            "eval": "contains",
            "value": "cash register"
          }
        ]
      }
    ],
  }
}
```

**Joe says** I'd like to think more deeply about how to determine column names for columns generated through a lookup or through other means. The column name will be useful as a column name in the resulting output file, and elsewhere in the transformation definition.

### Perform Key: `convert`

Use a formula to change the data contained in a column. This key can contain a single object or an array of objects. Each object must contain the following keys:

Key Name | Expected Value
-------- | --------------
column | The name of the Input column to convert
formula | A Convert formula object. A list of available conversion functions and their formats is listed, below.

**Conversion Functions**

Function (key) Name | Expected Value Format | Notes
------------------- | --------------------- | -----
concat | [field_name, string, field_name, ...]
add | [field_name, int, field_name, ...]
subtract | [field_name, int, field_name, ...]
multiply | [field_name, int, field_name, ...]
divide | [field_name, int]
exp | [field_name, int]
invert | invert_type or {value_to_flip: flipped_value} | Invert types could be: boolean, yn
self | | Pass the value through unmodified (**placeholder** this might not be needed)
other | field_name | Pass the value from another field
time-values | \*\*NOW\*\*, \*\*TOMORROW\*\*, {past: time_period}, {future: time_period} | time_period = "2 Months" "1 Year" etc.
custom | ssn, date, name_split

**Note:** Field names should be enclosed in double-asterisks.

**Examples**

```json
{
  "convert": {
    "column": "employment_type",
    "formula": {
      "invert": {
        "FT": "Full Time",
        "PT": "Part Time"
    }
  }
}
```

### Perform Key: `derive`

Create a new column in the Output and populate the column with values based on a formula. This key can contain a single object or an array of objects. Each object must contain the following keys:

Key Name | Expected Value
-------- | --------------
name | The name of the column. This is also known as the header.
formula | A Derive formula object. A list of available derive functions and their formats is listed, below.

**Derive Functions**

Function (key) Name | Expected Value Format | Notes
------------------- | --------------------- | -----
concat | [field_name, string, field_name, ...]
add | [field_name, int, field_name, ...]
subtract | [field_name, int, field_name, ...]
multiply | [field_name, int, field_name, ...]
divide | [field_name, int]
exp | [field_name, int]
invert | invert_type or {value_to_flip: flipped_value} | Invert types could be: boolean, yn
other | field_name | Pass the value from another field
time-values | \*\*NOW\*\*, \*\*TOMORROW\*\*, {past: time_period}, {future: time_period} | time_period = "2 Months" "1 Year" etc.
custom | ssn, date, name_split

**Note:** Field names should be enclosed in double-asterisks.

**Example**

```json
{
  "derive": {
    "name": "full_name",
    "formula": {
      "concat": [ "**first_name**", " ", "**last_name**" ]
    }
  }
}
```

### Perform Key: `aggregate`

Turn the Output into an aggregate report. This key can only contain a single object, not an array. To create an aggregate report on multiple numeric fields, use an array inside the `formula` key in the object (example, below).

This report shows the average pay and contribution per pay period, grouped by department and employee.

The `aggregate` key must contain an object with the following keys:

Function (key) Name | Expected Value | Notes
------------------- | -------------- | -----
group_by | [ field_name, field_name ] | (optional) Can be a single field, or array of fields. If group_by is omitted, the Output is a single record aggregate of all the fields.
formula | { function_name: input_column_name, as: output_column_name } | Can be a single object, or an array of objects. Available functions: average, count, max, min, sum

**Example**

```json
{
  "aggregate": { 
    "group_by": ["department", "employee"],
    "formula": [
      { "average": "gross_pay", "as": "average_pay"},
      { "average": "employer_contribution", "as": "average_contribution" }
    ]
  }
}
```

department | employee | average_pay | average_contribution
---------- | -------- | ----------- | --------------------
Accounting | Betty Bookkeeper | $3,419 | $275
Accounting | Casey Counter | $3,419 | $275
Sales | Joe Closer | $4,392 | $243
Sales | Sean Lemon | $3,992 | $256
etc | ... | ... | ...

### Perform Key: `map`

Define field mappings between Input and new columns generated through calculations, and Output.

This key should contain only a single object with the Input/Generated columns as keys and Output columns as values. Any columns that are excluded from the `map` will not be included in the output. Therefore, make sure to include all columns in your map.

**Example**

```json
{
  "map": {
    "ssn": "ssn",
    "name_first": "first_name",
    "name_last": "last_name"
  }
}
```

## Example Transformations

### Loading Employee Data, with a Lookup

This transformation accepts an employee data file as Input and creates a new file with the same data in a different format as Output. This transformation will include union membership status data from a separate File Drop, with the employee ID used as the key that matches the records in each data set. The `employee_ssn` column is also converted to ensure the `ssn` column in the Output is in the proper format for a Social Security number.

```json
{
  "version": 2,
  "save_output": "true",
  "perform": {
    "lookup": {
      "input_key": "employee_id",
      "lookup_source": { "file_drop": "employee_union_status.csv" },
      "lookup_key": "emp_id"
    },
    "convert": {
      "column": "employee_ssn",
      "formula": { "custom": "ssn" }
    },
    "map": {
      "employee_ssn": "ssn",
      "employee_id": "employee_id",
      "first_name": "first_name",
      "middle_name": "middle_name",
      "last_name": "last_name",
      "address_line_1": "address_1",
      "address_line_2": "address_2",
      "city": "city",
      "state": "state",
      "zip_code": "zip",
      "email_address": "email",
      "lookup_employee_union_status_csv_union_status": "union_status"
    }
  }
}
```

### Changing a Yes/No Flag

This transformation accepts a data file that includes a single column that needs to be converted from one standard to another. In this case, Input entries marked with a "Y" are left blank in the Output. Input entries that are blank or marked with an "N" are marked with a "Y" in the Output. All other data is passed through to the Output, unchanged.

```json
{
  "version": 2,
  "save_output": "true",
  "perform": {
    "convert": {
      "column": "waive_flag",
      "formula": { null: "Y", "N": "Y", "Y": null }
    }
  }
}
```


